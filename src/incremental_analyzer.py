#!/usr/bin/env python3
"""
Incremental Code Analyzer - å¢é‡ä»£ç åˆ†æå™¨
åªåˆ†ææ–°å¢æˆ–ä¿®æ”¹çš„ä»£ç æ–‡ä»¶ï¼Œé¿å…é‡å¤åˆ†æ
"""

import os
import sys
import json
import hashlib
from typing import List, Dict, Set, Optional
from datetime import datetime
from pathlib import Path

# Add the src directory to the python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from llm.ollama_client import OllamaClient
from llm.git_analyzer import GitAnalyzer
from directory_scanner import DirectoryScanner


class AnalysisCache:
    """åˆ†æç»“æœç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir: str):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        Args:
            cache_dir: ç¼“å­˜ç›®å½•è·¯å¾„
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.cache_file = self.cache_dir / "analysis_cache.json"
        self.cache_data = self._load_cache()
    
    def _load_cache(self) -> Dict:
        """åŠ è½½ç¼“å­˜æ•°æ®"""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸  åŠ è½½ç¼“å­˜å¤±è´¥: {e}ï¼Œå°†åˆ›å»ºæ–°ç¼“å­˜")
        return {
            'version': '1.0',
            'last_update': None,
            'files': {}
        }
    
    def _save_cache(self):
        """ä¿å­˜ç¼“å­˜æ•°æ®"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def _calculate_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶å†…å®¹çš„ MD5 å“ˆå¸Œå€¼"""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except Exception as e:
            print(f"âš ï¸  è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥ {file_path}: {e}")
            return ""
    
    def is_file_changed(self, file_path: str) -> bool:
        """
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²æ›´æ”¹
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            True å¦‚æœæ–‡ä»¶æ˜¯æ–°çš„æˆ–å·²ä¿®æ”¹ï¼ŒFalse å¦‚æœæ–‡ä»¶æœªæ›´æ”¹
        """
        abs_path = str(Path(file_path).resolve())
        current_hash = self._calculate_file_hash(file_path)
        
        if not current_hash:
            return True  # æ— æ³•è¯»å–æ–‡ä»¶ï¼Œè§†ä¸ºå·²æ›´æ”¹
        
        # æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦å­˜åœ¨è¯¥æ–‡ä»¶
        if abs_path not in self.cache_data['files']:
            return True  # æ–°æ–‡ä»¶
        
        cached_info = self.cache_data['files'][abs_path]
        return cached_info.get('hash') != current_hash
    
    def update_file_cache(self, file_path: str, analysis_result: Dict):
        """
        æ›´æ–°æ–‡ä»¶ç¼“å­˜ä¿¡æ¯
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            analysis_result: åˆ†æç»“æœ
        """
        abs_path = str(Path(file_path).resolve())
        file_hash = self._calculate_file_hash(file_path)
        
        self.cache_data['files'][abs_path] = {
            'hash': file_hash,
            'last_analyzed': datetime.now().isoformat(),
            'status': analysis_result.get('status', 'unknown'),
            'language': analysis_result.get('language', 'unknown')
        }
        self.cache_data['last_update'] = datetime.now().isoformat()
        self._save_cache()
    
    def get_cached_files(self) -> List[str]:
        """è·å–æ‰€æœ‰å·²ç¼“å­˜çš„æ–‡ä»¶åˆ—è¡¨"""
        return list(self.cache_data['files'].keys())
    
    def remove_file_cache(self, file_path: str):
        """åˆ é™¤æ–‡ä»¶ç¼“å­˜"""
        abs_path = str(Path(file_path).resolve())
        if abs_path in self.cache_data['files']:
            del self.cache_data['files'][abs_path]
            self._save_cache()
    
    def clear_cache(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        self.cache_data = {
            'version': '1.0',
            'last_update': None,
            'files': {}
        }
        self._save_cache()
        print("âœ“ ç¼“å­˜å·²æ¸…ç©º")
    
    def get_statistics(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_cached_files': len(self.cache_data['files']),
            'last_update': self.cache_data.get('last_update'),
            'cache_file': str(self.cache_file)
        }


class IncrementalAnalyzer:
    """å¢é‡ä»£ç åˆ†æå™¨"""
    
    def __init__(self, root_dir: str, output_dir: str = None, cache_dir: str = None,
                 extensions: List[str] = None, use_git: bool = True):
        """
        åˆå§‹åŒ–å¢é‡åˆ†æå™¨
        
        Args:
            root_dir: é¡¹ç›®æ ¹ç›®å½•
            output_dir: åˆ†ææŠ¥å‘Šè¾“å‡ºç›®å½•
            cache_dir: ç¼“å­˜ç›®å½•ï¼ˆé»˜è®¤ä¸º output_dir/.cacheï¼‰
            extensions: è¦åˆ†æçš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨
            use_git: æ˜¯å¦ä½¿ç”¨ Git æ¥æ£€æµ‹å˜æ›´
        """
        self.root_dir = Path(root_dir).resolve()
        self.output_dir = Path(output_dir) if output_dir else self.root_dir / "incremental_reports"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–ç¼“å­˜
        cache_path = cache_dir if cache_dir else self.output_dir / ".cache"
        self.cache = AnalysisCache(str(cache_path))
        
        # åˆå§‹åŒ–æ‰«æå™¨
        self.scanner = DirectoryScanner(
            root_dir=str(self.root_dir),
            output_dir=str(self.output_dir),
            extensions=extensions
        )
        
        # åˆå§‹åŒ– Git åˆ†æå™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.use_git = use_git
        self.git_analyzer = None
        if use_git:
            try:
                self.git_analyzer = GitAnalyzer(str(self.root_dir))
                print("âœ“ Git ä»“åº“æ£€æµ‹æˆåŠŸï¼Œå°†ä½¿ç”¨ Git æ¥æ£€æµ‹æ–‡ä»¶å˜æ›´\n")
            except ValueError:
                print("âš ï¸  ä¸æ˜¯ Git ä»“åº“ï¼Œå°†ä½¿ç”¨æ–‡ä»¶å“ˆå¸Œæ¥æ£€æµ‹å˜æ›´\n")
                self.use_git = False
        
        self.ollama_client = OllamaClient()
        self.stats = {
            'total_files': 0,
            'new_files': 0,
            'modified_files': 0,
            'unchanged_files': 0,
            'analyzed_files': 0,
            'failed_files': 0
        }
    
    def get_changed_files_from_git(self, since_commit: str = None) -> Set[str]:
        """
        ä» Git è·å–å·²æ›´æ”¹çš„æ–‡ä»¶åˆ—è¡¨
        
        Args:
            since_commit: èµ·å§‹æäº¤å“ˆå¸Œï¼ˆé»˜è®¤ä¸ºä¸Šæ¬¡æäº¤ï¼‰
            
        Returns:
            å·²æ›´æ”¹æ–‡ä»¶çš„è·¯å¾„é›†åˆ
        """
        if not self.git_analyzer:
            return set()
        
        try:
            changed_files = self.git_analyzer.get_changed_files(since_commit)
            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            return {str((self.root_dir / f).resolve()) for f in changed_files if f}
        except Exception as e:
            print(f"âš ï¸  è·å– Git å˜æ›´å¤±è´¥: {e}")
            return set()
    
    def scan_and_filter_files(self, force_all: bool = False) -> Dict[str, List[str]]:
        """
        æ‰«æç›®å½•å¹¶è¿‡æ»¤å‡ºéœ€è¦åˆ†æçš„æ–‡ä»¶
        
        Args:
            force_all: æ˜¯å¦å¼ºåˆ¶åˆ†ææ‰€æœ‰æ–‡ä»¶
            
        Returns:
            åˆ†ç±»åçš„æ–‡ä»¶å­—å…¸ï¼š{'new': [...], 'modified': [...], 'unchanged': [...]}
        """
        print("ğŸ” å¼€å§‹æ‰«æé¡¹ç›®æ–‡ä»¶...\n")
        
        all_files = self.scanner.scan_directory()
        self.stats['total_files'] = len(all_files)
        
        categorized = {
            'new': [],
            'modified': [],
            'unchanged': []
        }
        
        if force_all:
            print("âš¡ å¼ºåˆ¶åˆ†ææ¨¡å¼ï¼šå°†åˆ†ææ‰€æœ‰æ–‡ä»¶\n")
            categorized['modified'] = all_files
            self.stats['modified_files'] = len(all_files)
            return categorized
        
        # è·å– Git å˜æ›´çš„æ–‡ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        git_changed_files = self.get_changed_files_from_git() if self.use_git else set()
        
        print("ğŸ“Š æ­£åœ¨åˆ†ç±»æ–‡ä»¶...\n")
        for file_path in all_files:
            abs_path = str(Path(file_path).resolve())
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨ç¼“å­˜ä¸­
            is_cached = abs_path in self.cache.get_cached_files()
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²æ›´æ”¹
            if self.use_git and git_changed_files:
                # ä½¿ç”¨ Git æ£€æµ‹
                is_changed = abs_path in git_changed_files
            else:
                # ä½¿ç”¨æ–‡ä»¶å“ˆå¸Œæ£€æµ‹
                is_changed = self.cache.is_file_changed(file_path)
            
            if not is_cached:
                categorized['new'].append(file_path)
                self.stats['new_files'] += 1
            elif is_changed:
                categorized['modified'].append(file_path)
                self.stats['modified_files'] += 1
            else:
                categorized['unchanged'].append(file_path)
                self.stats['unchanged_files'] += 1
        
        return categorized
    
    def analyze_incremental(self, force_all: bool = False, verbose: bool = True) -> List[Dict]:
        """
        æ‰§è¡Œå¢é‡åˆ†æ
        
        Args:
            force_all: æ˜¯å¦å¼ºåˆ¶åˆ†ææ‰€æœ‰æ–‡ä»¶
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        print("="*80)
        print("ğŸš€ å¢é‡ä»£ç åˆ†æå™¨")
        print("="*80)
        print(f"é¡¹ç›®ç›®å½•: {self.root_dir}")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"ç¼“å­˜ç›®å½•: {self.cache.cache_dir}")
        print("="*80 + "\n")
        
        # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
        cache_stats = self.cache.get_statistics()
        print(f"ğŸ“¦ ç¼“å­˜ä¿¡æ¯:")
        print(f"  - å·²ç¼“å­˜æ–‡ä»¶: {cache_stats['total_cached_files']}")
        print(f"  - ä¸Šæ¬¡æ›´æ–°: {cache_stats['last_update'] or 'ä»æœª'}")
        print()
        
        # æ‰«æå¹¶åˆ†ç±»æ–‡ä»¶
        categorized_files = self.scan_and_filter_files(force_all)
        
        # æ˜¾ç¤ºåˆ†ç±»ç»Ÿè®¡
        print("ğŸ“ˆ æ–‡ä»¶åˆ†ç±»ç»Ÿè®¡:")
        print(f"  - æ€»æ–‡ä»¶æ•°: {self.stats['total_files']}")
        print(f"  - æ–°æ–‡ä»¶: {self.stats['new_files']}")
        print(f"  - å·²ä¿®æ”¹: {self.stats['modified_files']}")
        print(f"  - æœªæ›´æ”¹: {self.stats['unchanged_files']}")
        print()
        
        # éœ€è¦åˆ†æçš„æ–‡ä»¶
        files_to_analyze = categorized_files['new'] + categorized_files['modified']
        
        if not files_to_analyze:
            print("âœ… æ²¡æœ‰éœ€è¦åˆ†æçš„æ–‡ä»¶ï¼æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯æœ€æ–°çš„ã€‚\n")
            return []
        
        print(f"ğŸ¯ å°†åˆ†æ {len(files_to_analyze)} ä¸ªæ–‡ä»¶\n")
        
        # åˆ†ææ–‡ä»¶
        results = []
        for i, file_path in enumerate(files_to_analyze, 1):
            print(f"\nè¿›åº¦: [{i}/{len(files_to_analyze)}]")
            
            # ä½¿ç”¨ DirectoryScanner çš„åˆ†ææ–¹æ³•
            result = self.scanner.analyze_file(file_path)
            results.append(result)
            
            # æ›´æ–°ç¼“å­˜
            if result['status'] == 'success':
                self.cache.update_file_cache(file_path, result)
                self.stats['analyzed_files'] += 1
            else:
                self.stats['failed_files'] += 1
        
        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        self._print_summary()
        
        # ä¿å­˜å¢é‡åˆ†ææŠ¥å‘Š
        self._save_incremental_report(categorized_files, results)
        
        return results
    
    def _print_summary(self):
        """æ‰“å°åˆ†æç»Ÿè®¡æ‘˜è¦"""
        print("\n" + "="*80)
        print("ğŸ“Š å¢é‡åˆ†æç»Ÿè®¡")
        print("="*80)
        print(f"æ‰«æçš„æ–‡ä»¶æ€»æ•°: {self.stats['total_files']}")
        print(f"æ–°æ–‡ä»¶: {self.stats['new_files']}")
        print(f"å·²ä¿®æ”¹æ–‡ä»¶: {self.stats['modified_files']}")
        print(f"æœªæ›´æ”¹æ–‡ä»¶: {self.stats['unchanged_files']}")
        print(f"æˆåŠŸåˆ†æ: {self.stats['analyzed_files']}")
        print(f"åˆ†æå¤±è´¥: {self.stats['failed_files']}")
        print("="*80)
    
    def _save_incremental_report(self, categorized_files: Dict, results: List[Dict]):
        """ä¿å­˜å¢é‡åˆ†ææŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = self.output_dir / f"incremental_report_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# å¢é‡ä»£ç åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**é¡¹ç›®ç›®å½•**: `{self.root_dir}`\n\n")
            f.write(f"**åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**åˆ†ææ¨¡å¼**: {'Git å˜æ›´æ£€æµ‹' if self.use_git else 'æ–‡ä»¶å“ˆå¸Œæ£€æµ‹'}\n\n")
            
            f.write("## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯\n\n")
            f.write(f"- æ‰«æçš„æ–‡ä»¶æ€»æ•°: {self.stats['total_files']}\n")
            f.write(f"- æ–°æ–‡ä»¶: {self.stats['new_files']}\n")
            f.write(f"- å·²ä¿®æ”¹æ–‡ä»¶: {self.stats['modified_files']}\n")
            f.write(f"- æœªæ›´æ”¹æ–‡ä»¶: {self.stats['unchanged_files']}\n")
            f.write(f"- æˆåŠŸåˆ†æ: {self.stats['analyzed_files']}\n")
            f.write(f"- åˆ†æå¤±è´¥: {self.stats['failed_files']}\n\n")
            
            # æ–°æ–‡ä»¶åˆ—è¡¨
            if categorized_files['new']:
                f.write("## ğŸ†• æ–°æ–‡ä»¶\n\n")
                for file_path in categorized_files['new']:
                    rel_path = os.path.relpath(file_path, self.root_dir)
                    f.write(f"- `{rel_path}`\n")
                f.write("\n")
            
            # å·²ä¿®æ”¹æ–‡ä»¶åˆ—è¡¨
            if categorized_files['modified']:
                f.write("## âœï¸ å·²ä¿®æ”¹æ–‡ä»¶\n\n")
                for file_path in categorized_files['modified']:
                    rel_path = os.path.relpath(file_path, self.root_dir)
                    f.write(f"- `{rel_path}`\n")
                f.write("\n")
            
            # åˆ†æç»“æœæ‘˜è¦
            f.write("## ğŸ“ åˆ†æç»“æœ\n\n")
            for result in results:
                status_emoji = "âœ…" if result['status'] == 'success' else "âŒ"
                f.write(f"{status_emoji} **{result['file_path']}** ({result['language']})\n")
                if result['error']:
                    f.write(f"   - é”™è¯¯: {result['error']}\n")
                f.write("\n")
        
        print(f"\nâœ“ å¢é‡åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    def clear_cache(self):
        """æ¸…ç©ºåˆ†æç¼“å­˜"""
        self.cache.clear_cache()
    
    def show_cache_info(self):
        """æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯"""
        stats = self.cache.get_statistics()
        print("\n" + "="*80)
        print("ğŸ“¦ ç¼“å­˜ä¿¡æ¯")
        print("="*80)
        print(f"ç¼“å­˜æ–‡ä»¶: {stats['cache_file']}")
        print(f"å·²ç¼“å­˜æ–‡ä»¶æ•°: {stats['total_cached_files']}")
        print(f"ä¸Šæ¬¡æ›´æ–°: {stats['last_update'] or 'ä»æœª'}")
        print("="*80 + "\n")
        
        if stats['total_cached_files'] > 0:
            print("å·²ç¼“å­˜çš„æ–‡ä»¶åˆ—è¡¨:")
            for i, file_path in enumerate(self.cache.get_cached_files()[:10], 1):
                print(f"  {i}. {file_path}")
            if stats['total_cached_files'] > 10:
                print(f"  ... è¿˜æœ‰ {stats['total_cached_files'] - 10} ä¸ªæ–‡ä»¶")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='å¢é‡ä»£ç åˆ†æå™¨ - åªåˆ†ææ–°å¢æˆ–ä¿®æ”¹çš„ä»£ç æ–‡ä»¶',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¢é‡åˆ†æå½“å‰ç›®å½•
  python3 src/incremental_analyzer.py . -o reports
  
  # å¼ºåˆ¶åˆ†ææ‰€æœ‰æ–‡ä»¶
  python3 src/incremental_analyzer.py . -o reports --force
  
  # åªåˆ†æ Python å’Œ Java æ–‡ä»¶
  python3 src/incremental_analyzer.py . -o reports -e .py .java
  
  # æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯
  python3 src/incremental_analyzer.py . --show-cache
  
  # æ¸…ç©ºç¼“å­˜
  python3 src/incremental_analyzer.py . --clear-cache
        """
    )
    
    parser.add_argument('directory', help='è¦åˆ†æçš„é¡¹ç›®ç›®å½•')
    parser.add_argument('-o', '--output', dest='output_dir', help='åˆ†ææŠ¥å‘Šè¾“å‡ºç›®å½•')
    parser.add_argument('-c', '--cache-dir', dest='cache_dir', help='ç¼“å­˜ç›®å½•ï¼ˆé»˜è®¤ä¸ºè¾“å‡ºç›®å½•/.cacheï¼‰')
    parser.add_argument('-e', '--extensions', nargs='+', help='è¦åˆ†æçš„æ–‡ä»¶æ‰©å±•åï¼ˆä¾‹å¦‚: .py .java .jsï¼‰')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶åˆ†ææ‰€æœ‰æ–‡ä»¶ï¼Œå¿½ç•¥ç¼“å­˜')
    parser.add_argument('--no-git', action='store_true', help='ä¸ä½¿ç”¨ Git æ£€æµ‹å˜æ›´ï¼Œåªä½¿ç”¨æ–‡ä»¶å“ˆå¸Œ')
    parser.add_argument('--show-cache', action='store_true', help='æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯')
    parser.add_argument('--clear-cache', action='store_true', help='æ¸…ç©ºç¼“å­˜')
    
    args = parser.parse_args()
    
    try:
        analyzer = IncrementalAnalyzer(
            root_dir=args.directory,
            output_dir=args.output_dir,
            cache_dir=args.cache_dir,
            extensions=args.extensions,
            use_git=not args.no_git
        )
        
        if args.show_cache:
            analyzer.show_cache_info()
            return
        
        if args.clear_cache:
            analyzer.clear_cache()
            return
        
        analyzer.analyze_incremental(force_all=args.force)
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
